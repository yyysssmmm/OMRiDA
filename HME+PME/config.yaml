experiment_name: "dla_baseline"

# ✅ 데이터 경로
data:
  vocab: "data/vocab/crohme_vocab.txt"
  paired:
    hme_img: "data/preprocessed/train/paired/crohme/hme"
    pme_img: "data/preprocessed/train/paired/crohme/pme"
    caption: "data/preprocessed/train/paired/crohme/caption.txt"
  unpaired:
    pme_img: "data/preprocessed/train/paired/im2latex/pme"
    caption: "data/preprocessed/train/paired/im2latex/caption.txt"

# ✅ 모델 하이퍼파라미터
model:
  emb_dim: 64
  encoder_out_channels: 512
  decoder_hidden_dim: 256
  attention_dim: 256

# ✅ 학습 설정
training:
  batch_size: 1
  epochs: 100
  learning_rate: 0.1
  match_weight: 1.0
  optimizer: "adadelta"         
  grad_clip: 5.0
  early_stop_patience: 5
  ignore_idx: 0

  scheduler:
    use: true
    type: "StepLR"
    step_size: 10
    gamma: 0.5

# ✅ 이미지 전처리 설정
transforms:
  paired_hme:
    target_size: [481, 2116] # width, height 순서가 아니라 height, width 순서임에 유의 
    mean: [0.0770]
    std: [0.2633]

  paired_pme:
    target_size: [125, 872]
    mean: [0.8126]
    std: [0.3817]

  unpaired:
    target_size: [2339, 1654]
    mean: [0.9994]
    std: [0.0246]


# ✅ 테스트 설정
testing:
  batch_size: 1
  max_len: 150

# ✅ 기타 설정
misc:
  seed: 42
  device: "mps"   # "cuda" / "cpu"
  checkpoint_path: "runs/dla_baseline_bs1_lr0.1_match1.0_schedStepLR10_0.5_seed42/batch_logs/epoch001_batch2965.pt"
  batch_log_path: "runs/dla_baseline_bs1_lr0.1_match1.0_schedStepLR10_0.5_seed42/batch_logs/epoch001_batch2965.pt"
