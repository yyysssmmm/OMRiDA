import os
import json
import yaml
import argparse
from pathlib import Path
from tqdm import tqdm
import torch
from torch.utils.data import DataLoader

from models.dla import DLAModel
from data.dataset import FormulaDataset
from data.utils.vocab import Vocab
from utils.metrics import exprate_k, cer
from utils.decode import decode_sequence
from utils.seed import set_seed
from utils.data_utils import get_formula_transform, formula_collate_fn

# âœ… config.yaml ë¶ˆëŸ¬ì˜¤ê¸°
def load_config(path):
    with open(path, "r") as f:
        return yaml.safe_load(f)

parser = argparse.ArgumentParser()
parser.add_argument("--config", type=str, default="config.yaml")
args = parser.parse_args()
config = load_config(args.config)

# âœ… ê¸°ë³¸ ì„¤ì •ê°’ ë¡œë“œ
set_seed(config["misc"]["seed"])
IGNORE_IDX = config["training"]["ignore_idx"]
BATCH_SIZE = config["testing"].get("batch_size", 1)
MAX_LEN = config["testing"].get("max_len", 150)
TEST_YEARS = ["2014", "2016", "2019"]
CHECKPOINT_PATH = config["misc"]["batch_log_path"]
VOCAB_PATH = config["data"]["vocab"]
DEVICE = torch.device(config["misc"]["device"] if torch.backends.mps.is_available() or torch.cuda.is_available() else "cpu")

# âœ… ê²°ê³¼ ë””ë ‰í† ë¦¬
os.makedirs("preds", exist_ok=True)

# âœ… vocab ë° ëª¨ë¸ ë¡œë“œ
vocab = Vocab.load_from_txt(Path(VOCAB_PATH))
SOS_ID = vocab.token2idx["<sos>"]
EOS_ID = vocab.token2idx["<eos>"]

model_config = config["model"]
unpaired_model = DLAModel(vocab_size=len(vocab), model_config=model_config).to(DEVICE)

checkpoint = torch.load(CHECKPOINT_PATH, map_location=DEVICE)
unpaired_model.load_state_dict(checkpoint["model_state_dict"])
unpaired_model.eval()

# âœ… í‰ê°€ í•¨ìˆ˜ ì •ì˜
def evaluate(img_dir, caption_path, img_ext, mode="hme"):
    assert mode in ["hme", "pme"], f"âŒ Invalid mode: {mode}"

    transform = get_formula_transform("paired_hme" if mode == "hme" else "paired_pme", config["transforms"])
    dataset = FormulaDataset(
        image_dir=img_dir,
        caption_path=caption_path,
        transform=transform,
        image_ext=img_ext,
        vocab=vocab
    )
    dataloader = DataLoader(
        dataset,
        batch_size=BATCH_SIZE,
        shuffle=False,
        collate_fn=lambda b: formula_collate_fn(b, pad_idx=IGNORE_IDX)
    )

    preds, targets = [], []
    debug_lines = []

    with torch.no_grad():
        for batch in tqdm(dataloader, desc=f"{mode.upper()} Eval"):
            imgs = batch["image"].to(DEVICE)
            tgt_ids = batch["formula"]

            pred_ids_batch = unpaired_model.predict(imgs, max_len=MAX_LEN, sos_idx=SOS_ID, eos_idx=EOS_ID)
            pred_tokens_batch = decode_sequence(pred_ids_batch, vocab)
            target_tokens_batch = decode_sequence(tgt_ids, vocab)

            preds.extend(pred_tokens_batch)
            targets.extend(target_tokens_batch)

            for pred, target in zip(pred_tokens_batch, target_tokens_batch):
                debug_lines.append(f"[GT]   {' '.join(target)}")
                debug_lines.append(f"[PRD]  {' '.join(pred)}")
                debug_lines.append("---")

    year = Path(img_dir).parts[-2]
    debug_path = f"preds/pred_target_pairs_{mode}_{year}.txt"
    with open(debug_path, "w", encoding="latin1") as f:
        f.write("\n".join(debug_lines))
    print(f"ğŸ“„ {mode.upper()} {year} ê²°ê³¼ ì €ì¥ë¨: {debug_path}")

    return preds, targets

# âœ… ê²°ê³¼ ì¶œë ¥ í•¨ìˆ˜
def print_result_section(title: str, result_dict: dict):
    print(f"\nğŸ“Š {title}")
    for key, val in result_dict.items():
        print(f"  {key}: {val}")

# âœ… ì „ì²´ í‰ê°€
result_log = {"CROHME": {"hme": {}, "pme": {}}, "IM2LATEX": {"pme":{}}}

# hme í‰ê°€
for year in TEST_YEARS:
    img_dir = f"data/preprocessed/test/hme/crohme/{year}/hme_img"
    caption_path = f"data/preprocessed/test/hme/crohme/{year}/caption.txt"
    preds, targets = evaluate(img_dir, caption_path, img_ext="bmp", mode="hme")

    result_log["CROHME"]["hme"][year] = {
        f"exprate_{k}": round(exprate_k(preds, targets, k), 4) for k in range(4)
    }
    result_log["CROHME"]["hme"][year]["cer"] = round(cer(preds, targets), 4)

# pme í‰ê°€
for year in TEST_YEARS:
    img_dir = f"data/preprocessed/test/pme/crohme/{year}/pme_img"
    caption_path = f"data/preprocessed/test/pme/crohme/{year}/caption.txt"
    preds, targets = evaluate(img_dir, caption_path, img_ext="png", mode="pme")

    result_log["CROHME"]["pme"][year] = {
        f"exprate_{k}": round(exprate_k(preds, targets, k), 4) for k in range(4)
    }
    result_log["CROHME"]["pme"][year]["cer"] = round(cer(preds, targets), 4)

# im2latex í‰ê°€
img_dir = f"data/preprocessed/test/pme/im2latex/img"
caption_path = f"data/preprocessed/test/pme/im2latex/caption.txt"
preds, targets = evaluate(img_dir, caption_path, img_ext="png", mode="pme")

result_log["IM2LATEX"]["pme"] = {
    f"exprate_{k}": round(exprate_k(preds, targets, k), 4) for k in range(4)
}
result_log["IM2LATEX"]["pme"]["cer"] = round(cer(preds, targets), 4)

# âœ… ì¶œë ¥
for year in TEST_YEARS:
    print_result_section(f"CROHME-HME {year}", result_log["CROHME"]["hme"][year])
    print_result_section(f"CROHME-PME {year}", result_log["CROHME"]["pme"][year])

print_result_section("IM2LATEX-PME", result_log["IM2LATEX"]["pme"])

# âœ… ì „ì²´ ê²°ê³¼ ì €ì¥
with open("test_results.json", "w") as f:
    json.dump(result_log, f, indent=4)

print("\nâœ… í‰ê°€ ì™„ë£Œ! ê²°ê³¼ëŠ” test_results.jsonì— ì €ì¥ë¨")
